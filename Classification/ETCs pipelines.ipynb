{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import SelectPercentile, SelectKBest, f_regression, f_classif, chi2, VarianceThreshold\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecorrelator(BaseEstimator, TransformerMixin): \n",
    "    \n",
    "    def __init__(self, threshold):\n",
    "        self.threshold = threshold\n",
    "        self.correlated_columns = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        correlated_features = set()  \n",
    "        X = pd.DataFrame(X)\n",
    "        corr_matrix = X.corr()\n",
    "        for i in range(len(corr_matrix.columns)):\n",
    "            for j in range(i):\n",
    "                if abs(corr_matrix.iloc[i, j]) > self.threshold: # we are interested in absolute coeff value\n",
    "                    colname = corr_matrix.columns[i]  # getting the name of column\n",
    "                    correlated_features.add(colname)\n",
    "        self.correlated_features = correlated_features\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, **kwargs):\n",
    "        return (pd.DataFrame(X)).drop(labels=self.correlated_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_excel(r'database.xlsx', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16763/16763 [00:00<00:00, 171001.84it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "rows_to_drop = []\n",
    "for i in tqdm.tqdm(range(len(Data))):\n",
    "    if 'Cu' in Data.index[i] or 'Fe' in Data.index[i] or 'Ni' in Data.index[i] or 'O' in Data.index[i] or Data['Tc'].iloc[i]>50:\n",
    "        rows_to_drop.append(Data.index[i])\n",
    "        \n",
    "data_reduced = Data.drop(rows_to_drop)\n",
    "\n",
    "data_reduced['class'] = 0\n",
    "for i in range(len(data_reduced)):\n",
    "    if data_reduced['Tc'].iloc[i] >= 15:\n",
    "        data_reduced['class'].iloc[i] = 1\n",
    "        \n",
    "data = data_reduced.drop('Tc', axis = 1)\n",
    "\n",
    "train_df, test_df = train_test_split(data, test_size = 0.15, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Pipeline for ETC-vanilla'''\n",
    "\n",
    "etc = ExtraTreesClassifier(random_state = 0)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('decorrelation', MyDecorrelator(0.9)), \n",
    "    ('threshold', VarianceThreshold(threshold = 0)), \n",
    "    ('feature_selector', SelectPercentile(f_classif)), \n",
    "    ('etc', etc)\n",
    "], verbose = 1)\n",
    "\n",
    "param_grid = {\n",
    "    \"etc__n_estimators\": [100, 250, 500, 750, 1000],    #Tune the number of estimators\n",
    "    \"etc__max_features\": [1, 0.9, 0.8, 0.7, 0.6, 0.5],  #Tune the number of features to consider when looking for the best split\n",
    "    \"feature_selector__percentile\": [50, 75, 100]       #Tune the percentage of features to retain in terms of f_regression score\n",
    "}\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state = 0)\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=-1, verbose = 1, cv = stratified_kfold)\n",
    "search.fit(train_df.iloc[:, :-1], train_df.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Pipeline for ETC-SMOTE'''\n",
    "\n",
    "etc = ExtraTreesClassifier(random_state = 0)\n",
    "\n",
    "pipe = imbpipeline([\n",
    "    ('decorrelation', MyDecorrelator(0.9)), \n",
    "    ('threshold', VarianceThreshold(threshold = 0)), \n",
    "    ('smote', SMOTE(random_state = 0)),\n",
    "    ('feature_selector', SelectPercentile(f_classif)), \n",
    "    ('etc', etc)\n",
    "], verbose = 1)\n",
    "\n",
    "param_grid = {\n",
    "    \"etc__n_estimators\": [100, 250, 500, 750, 1000],                   \n",
    "    \"etc__max_features\": [1, 0.9, 0.8, 0.7, 0.6, 0.5],  \n",
    "    \"feature_selector__percentile\": [50, 75, 100]             \n",
    "}\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state = 0)\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=-1, verbose = 1, cv = stratified_kfold)\n",
    "search.fit(train_df.iloc[:, :-1], train_df.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Pipeline for ETC-vanilla 81'''\n",
    "\n",
    "SHAP = pd.read_excel(r'SHAP_for_ETR_metallic_mean.xlsx', index_col = 0)\n",
    "train_data = data[SHAP.index[0:81]]\n",
    "train_data['class'] = data['class']\n",
    "train_df, test_df = train_test_split(train_data, test_size = 0.15, random_state = 0)\n",
    "\n",
    "etc = ExtraTreesClassifier(random_state = 0)\n",
    "\n",
    "pipe = Pipeline([ \n",
    "    ('etc', etc)\n",
    "], verbose = 1)\n",
    "\n",
    "param_grid = {\n",
    "    \"etc__n_estimators\": [100, 250, 500, 750, 1000],  \n",
    "    \"etc__max_features\": [1, 0.9, 0.8, 0.7, 0.6, 0.5],\n",
    "}\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state = 0)\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=-1, verbose = 1, cv = stratified_kfold)\n",
    "search.fit(train_df.iloc[:, :-1], train_df.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Pipeline for ETC-SMOTE 81'''\n",
    "\n",
    "SHAP = pd.read_excel(r'SHAP_for_ETR_metallic_mean.xlsx', index_col = 0)\n",
    "train_data = data[SHAP.index[0:81]]\n",
    "train_data['class'] = data['class']\n",
    "train_df, test_df = train_test_split(train_data, test_size = 0.15, random_state = 0)\n",
    "\n",
    "\n",
    "etc = ExtraTreesClassifier(random_state = 0)\n",
    "\n",
    "pipe = imbpipeline([\n",
    "    ('smote', SMOTE(random_state = 0)),\n",
    "    ('etc', etc)\n",
    "], verbose = 1)\n",
    "\n",
    "param_grid = {\n",
    "    \"etc__n_estimators\": [100, 250, 500, 750, 1000], \n",
    "    \"etc__max_features\": [1, 0.9, 0.8, 0.7, 0.6, 0.5],\n",
    "\n",
    "}\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state = 0)\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=-1, verbose = 1, cv = stratified_kfold)\n",
    "search.fit(train_df.iloc[:, :-1], train_df.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Pipeline for any ETC 2D/3D'''\n",
    "\n",
    "etc = ExtraTreesClassifier(random_state = 0)\n",
    "pipe = Pipeline([\n",
    "    ('etc', etc)\n",
    "], verbose = 1)\n",
    "\n",
    "param_grid = {\n",
    "    \"etc__n_estimators\": [100, 250, 500, 750, 1000]\n",
    "}\n",
    "\n",
    "stratified_kfold= StratifiedKFold(n_splits=5, shuffle=True, random_state = 0)\n",
    "search= GridSearchCV(pipe, param_grid, n_jobs=3, verbose = 1, cv = stratified_kfold)\n",
    "search.fit(train_df.iloc[:, :-1], train_df.iloc[:, -1])\n",
    "\n",
    "'''\n",
    "For ETC 2D high the features are ['MagpieData range MeltingT', '0-norm']\n",
    "For ETC 3D high the features are ['MagpieData range MeltingT' '0-norm', 'MagpieData mode NdUnfilled']\n",
    "\n",
    "For ETC 2D middle the features are ['MagpieData mode SpaceGroupNumber', 'MagpieData mode NpValence']\n",
    "For ETC 3D middle the features are ['MagpieData mode SpaceGroupNumber', 'MagpieData mode NpValence', 'MagpieData mean Column']\n",
    "\n",
    "For ETC 2D low the features are ['MagpieData minimum NfValence', 'MagpieData mode GSmagmom']\n",
    "For ETC 3D low the features are ['MagpieData minimum NfValence', 'MagpieData mode GSmagmom', 'MagpieData mode NfUnfilled']\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
